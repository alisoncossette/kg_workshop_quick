{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Patterns with Neo4j\n",
    "\n",
    "This notebook demonstrates how to use Neo4j's GraphRAG library to implement retrieval-augmented generation with graph context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings\n",
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "from neo4j_graphrag.retrievers import VectorRetriever, VectorCypherRetriever\n",
    "from neo4j_graphrag import GraphRAG, RagTemplate\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Neo4j connection\n",
    "URI = os.getenv('NEO4J_URI')\n",
    "AUTH = (os.getenv('NEO4J_USERNAME'), os.getenv('NEO4J_PASSWORD'))\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Create Neo4j driver\n",
    "driver = GraphDatabase.driver(URI, auth=AUTH)\n",
    "\n",
    "# Initialize LLM and embeddings\n",
    "llm = OpenAILLM(\n",
    "    model_name=\"gpt-4\",\n",
    "    model_params={\n",
    "        \"temperature\": 0  # Lower temperature for more deterministic results\n",
    "    }\n",
    ")\n",
    "\n",
    "embedder = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Index\n",
    "\n",
    "First, let's create a vector index for our documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index for document embeddings\n",
    "create_vector_index(\n",
    "    driver,\n",
    "    name=\"document_embeddings\",\n",
    "    label=\"Document\",\n",
    "    embedding_property=\"embedding\",\n",
    "    dimensions=1536,\n",
    "    similarity_fn=\"cosine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 1: Simple Vector Retrieval\n",
    "\n",
    "Let's start with basic vector similarity search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vector retriever\n",
    "vector_retriever = VectorRetriever(\n",
    "    driver,\n",
    "    index_name=\"document_embeddings\",\n",
    "    embedder=embedder,\n",
    "    return_properties=[\"text\", \"title\"]\n",
    ")\n",
    "\n",
    "# Create RAG template\n",
    "rag_template = RagTemplate(\n",
    "    template=\"\"\"Answer the Question using the following Context. Only respond with information mentioned in the Context.\n",
    "\n",
    "# Question:\n",
    "{query_text}\n",
    "\n",
    "# Context:\n",
    "{context}\n",
    "\n",
    "# Answer:\n",
    "\"\"\",\n",
    "    expected_inputs=['query_text', 'context']\n",
    ")\n",
    "\n",
    "# Initialize GraphRAG with vector retriever\n",
    "vector_rag = GraphRAG(llm=llm, retriever=vector_retriever, prompt_template=rag_template)\n",
    "\n",
    "# Example query\n",
    "question = \"What are the key features of our laptop products?\"\n",
    "result = vector_rag.search(question, retriever_config={'top_k': 3})\n",
    "print(f\"Answer: {result.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 2: Graph-Enhanced Retrieval\n",
    "\n",
    "Now let's use graph relationships to enhance our search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize graph-aware retriever\n",
    "graph_retriever = VectorCypherRetriever(\n",
    "    driver,\n",
    "    index_name=\"document_embeddings\",\n",
    "    embedder=embedder,\n",
    "    retrieval_query=\"\"\"\n",
    "    // Start with similar documents\n",
    "    WITH node AS doc\n",
    "    \n",
    "    // Get product information\n",
    "    MATCH (doc)-[:ABOUT]->(p:Product)\n",
    "    \n",
    "    // Get related support cases and manuals\n",
    "    OPTIONAL MATCH (p)<-[:ABOUT]-(support:Document)\n",
    "    WHERE support.type = 'support_case'\n",
    "    OPTIONAL MATCH (p)-[:HAS_MANUAL]->(manual:Document)\n",
    "    \n",
    "    // Return combined context\n",
    "    WITH collect(DISTINCT doc.text) + \n",
    "         collect(DISTINCT support.text) +\n",
    "         collect(DISTINCT manual.text) as texts\n",
    "    RETURN apoc.text.join(texts, '\\n') as info\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Initialize GraphRAG with graph retriever\n",
    "graph_rag = GraphRAG(llm=llm, retriever=graph_retriever, prompt_template=rag_template)\n",
    "\n",
    "# Example query using graph context\n",
    "question = \"What are common issues with the Laptop Pro model and their solutions?\"\n",
    "result = graph_rag.search(question, retriever_config={'top_k': 3})\n",
    "print(f\"Answer: {result.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 3: Multi-Hop Knowledge Retrieval\n",
    "\n",
    "Let's use graph traversal to gather related information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize multi-hop retriever\n",
    "multihop_retriever = VectorCypherRetriever(\n",
    "    driver,\n",
    "    index_name=\"document_embeddings\",\n",
    "    embedder=embedder,\n",
    "    retrieval_query=\"\"\"\n",
    "    // Start with similar documents\n",
    "    WITH node AS doc\n",
    "    \n",
    "    // Get product and category information\n",
    "    MATCH (doc)-[:ABOUT]->(p:Product)-[:IN_CATEGORY]->(cat:Category)\n",
    "    \n",
    "    // Get related products in same category\n",
    "    MATCH (cat)<-[:IN_CATEGORY]-(related:Product)\n",
    "    WHERE related <> p\n",
    "    \n",
    "    // Get support cases for all related products\n",
    "    MATCH (related)<-[:ABOUT]-(support:Document)\n",
    "    WHERE support.type = 'support_case'\n",
    "    \n",
    "    // Return combined context with relationship information\n",
    "    WITH collect(DISTINCT doc.text) + \n",
    "         collect(DISTINCT support.text) as texts,\n",
    "         p.name as product,\n",
    "         cat.name as category,\n",
    "         collect(DISTINCT related.name) as related_products\n",
    "    \n",
    "    RETURN \n",
    "        apoc.text.join(texts, '\\n') +\n",
    "        '\\nProduct: ' + product +\n",
    "        '\\nCategory: ' + category +\n",
    "        '\\nRelated Products: ' + apoc.text.join(related_products, ', ') as info\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Initialize GraphRAG with multi-hop retriever\n",
    "multihop_rag = GraphRAG(llm=llm, retriever=multihop_retriever, prompt_template=rag_template)\n",
    "\n",
    "# Example query using multi-hop traversal\n",
    "question = \"What are common issues across our laptop product line?\"\n",
    "result = multihop_rag.search(question, retriever_config={'top_k': 3})\n",
    "print(f\"Answer: {result.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key GraphRAG Features Used\n",
    "\n",
    "1. **Vector Indexing**: Using Neo4j's vector search capabilities\n",
    "2. **Vector Retrieval**: Basic similarity search using embeddings\n",
    "3. **Graph-Enhanced Retrieval**: Combining vector search with graph traversal\n",
    "4. **Cypher Integration**: Custom graph queries for context gathering\n",
    "5. **Multi-Hop Knowledge**: Traversing relationships to gather related information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

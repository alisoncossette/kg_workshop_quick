{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphRAG Patterns\n",
    "\n",
    "In this notebook, we'll explore advanced GraphRAG patterns that combine vector search with graph traversal. We'll cover:\n",
    "\n",
    "1. Graph-enhanced retrieval\n",
    "2. Text2Cypher for natural language queries\n",
    "3. Making AI decisions explainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "from neo4j_graphrag.embedder import OpenAIEmbedder\n",
    "from neo4j_graphrag.retriever import VectorRetriever, VectorCypherRetriever\n",
    "from neo4j_graphrag.text2cypher import Text2Cypher\n",
    "\n",
    "# Setup\n",
    "load_dotenv()\n",
    "driver = GraphDatabase.driver(\n",
    "    os.getenv('NEO4J_URI'),\n",
    "    auth=(os.getenv('NEO4J_USERNAME'), os.getenv('NEO4J_PASSWORD'))\n",
    ")\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "llm = OpenAILLM()\n",
    "embedder = OpenAIEmbedder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Graph-Enhanced Retrieval\n",
    "\n",
    "Let's see how combining vector search with graph traversal improves results. Our graph contains:\n",
    "- Products (name, category, price)\n",
    "- Customers who placed orders\n",
    "- Orders linking customers to products\n",
    "- Documents (manuals and support cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector-cypher retriever for our tech support use case\n",
    "graph_retriever = VectorCypherRetriever(\n",
    "    driver=driver,\n",
    "    embedder=embedder,\n",
    "    node_label=\"Product\",\n",
    "    embedding_property=\"embedding\",\n",
    "    cypher_template=\"\"\"\n",
    "    MATCH (p:Product)\n",
    "    WHERE p.embedding IS NOT NULL\n",
    "    WITH p, gds.similarity.cosine(p.embedding, $query_embedding) AS score\n",
    "    WHERE score > 0.7\n",
    "    \n",
    "    // Enhance with graph context from our data model\n",
    "    OPTIONAL MATCH (p)<-[:ORDERED]-(o:Order)<-[:PLACED]-(c:Customer)\n",
    "    OPTIONAL MATCH (p)<-[:ABOUT]-(d:Document)\n",
    "    OPTIONAL MATCH (c)-[:PLACED]->(o2:Order)-[:ORDERED]->(p2:Product)\n",
    "    WHERE p2 <> p\n",
    "    \n",
    "    RETURN p.name as product_name,\n",
    "           p.category as category,\n",
    "           p.price as price,\n",
    "           score,\n",
    "           collect(DISTINCT d.content) as documentation,\n",
    "           collect(DISTINCT p2.name) as frequently_bought_with,\n",
    "           count(DISTINCT c) as customer_count\n",
    "    ORDER BY score DESC\n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Example queries using our product data\n",
    "queries = [\n",
    "    \"Find accessories commonly purchased with the Laptop Pro\",\n",
    "    \"Show me storage solutions with good customer satisfaction\",\n",
    "    \"What products are recommended for productivity setup?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    results = graph_retriever.retrieve(query)\n",
    "    \n",
    "    print(\"Graph-enhanced results (with context):\")\n",
    "    for r in results:\n",
    "        print(f\"\\nProduct: {r.product_name}\")\n",
    "        print(f\"Category: {r.category}\")\n",
    "        print(f\"Price: ${r.price}\")\n",
    "        print(f\"Relevance Score: {r.score:.2f}\")\n",
    "        print(f\"Documentation: {r.documentation[:200]}...\")  # Truncate long text\n",
    "        print(f\"Frequently Bought With: {r.frequently_bought_with}\")\n",
    "        print(f\"Number of Customers: {r.customer_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text2Cypher for Natural Language Queries\n",
    "\n",
    "Convert natural language to Cypher queries that understand our data model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Text2Cypher with our schema\n",
    "text2cypher = Text2Cypher(\n",
    "    driver=driver,\n",
    "    llm=llm,\n",
    "    schema_hint=\"\"\"\n",
    "    The graph contains:\n",
    "    - Products (name, category, price)\n",
    "    - Customers who placed orders\n",
    "    - Orders linking customers to products\n",
    "    - Documents (manuals and support cases)\n",
    "    \n",
    "    Common relationships:\n",
    "    - (Customer)-[:PLACED]->(Order)-[:ORDERED]->(Product)\n",
    "    - (Document)-[:ABOUT]->(Product)\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Natural language query examples based on our data\n",
    "nl_queries = [\n",
    "    \"What products do customers usually buy after purchasing the Laptop Pro?\",\n",
    "    \"Find products mentioned in support cases with positive feedback\",\n",
    "    \"Show me the most popular accessories based on order history\"\n",
    "]\n",
    "\n",
    "for query in nl_queries:\n",
    "    print(f\"\\nNatural Language Query: {query}\")\n",
    "    cypher = text2cypher.translate(query)\n",
    "    print(f\"Generated Cypher:\\n{cypher}\")\n",
    "    \n",
    "    with driver.session() as session:\n",
    "        results = session.run(cypher)\n",
    "        for record in results:\n",
    "            print(f\"Result: {record}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Making AI Decisions Explainable\n",
    "\n",
    "Let's make our recommendations transparent by explaining how we use graph data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_recommendation(query, results):\n",
    "    explanation_prompt = f\"\"\"\n",
    "    Query: {query}\n",
    "    \n",
    "    Results:\n",
    "    {results}\n",
    "    \n",
    "    Explain why these products were recommended, considering:\n",
    "    1. Product features and categories\n",
    "    2. Customer purchase patterns\n",
    "    3. Support case feedback\n",
    "    4. Technical compatibility\n",
    "    \"\"\"\n",
    "    \n",
    "    explanation = llm.generate(explanation_prompt)\n",
    "    return explanation\n",
    "\n",
    "# Example usage\n",
    "query = \"What should I buy to enhance my Laptop Pro setup?\"\n",
    "results = graph_retriever.retrieve(query)\n",
    "\n",
    "explanation = explain_recommendation(query, results)\n",
    "print(\"\\nExplanation of recommendations:\")\n",
    "print(explanation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
